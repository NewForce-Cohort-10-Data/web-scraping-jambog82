{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72eedc0-0e19-431b-a096-fc53660d0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1A\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Define URL\n",
    "url = \"https://realpython.github.io/fake-jobs/\"\n",
    "\n",
    "#GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "#Convert to BS object\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#Use .find()\n",
    "job_title_tag = soup.find(\"h2\", class_=\"title is-5\")\n",
    "\n",
    "#Clean tags\n",
    "job_title = job_title_tag.text.strip()\n",
    "\n",
    "print(\"First Job Title:\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946318b-c57e-4023-bbe7-d21a2a729561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1B Find class \"title is-5\"\n",
    "job_title_tags = soup.find_all(\"h2\", class_=\"title is-5\")\n",
    "\n",
    "#Get text from each tag for list\n",
    "job_titles = [tag.text.strip() for tag in job_title_tags]\n",
    "\n",
    "print(\"Job Titles:\", job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce974a35-4677-483d-8287-a595aa650c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1C Get companies, locations, and dates\n",
    "\n",
    "#Find all job cards\n",
    "job_cards = soup.find_all(\"div\", class_=\"card\")\n",
    "\n",
    "#Make list\n",
    "companies = []\n",
    "locations = []\n",
    "dates = []\n",
    "\n",
    "#Loop through each job card\n",
    "for card in job_cards:\n",
    "    \n",
    "    #Get the company name class \"subtitle is-6 company\"\n",
    "    company = card.find(\"h3\", class_=\"subtitle is-6 company\").text.strip()\n",
    "    companies.append(company)\n",
    "    \n",
    "    #Get location\n",
    "    location = card.find(\"p\", class_=\"location\").text.strip()\n",
    "    locations.append(location)\n",
    "    \n",
    "    #Get date\n",
    "    date = card.find(\"time\").text.strip()\n",
    "    dates.append(posting_date)\n",
    "\n",
    "#Print\n",
    "print(\"Companies:\", companies)\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Dates:\", dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147eca5-0732-45d1-aec7-86aca5362648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D Create a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "jobs_df = pd.DataFrame({\n",
    "    \"Job Title\": job_titles,\n",
    "    \"Company\": companies,\n",
    "    \"Location\": locations,\n",
    "    \"Date\": dates\n",
    "})\n",
    "\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd6c5e-e63d-4203-ba3f-e495d161e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2A Get \"Apply\" URLs\n",
    "apply_urls = []\n",
    "for card in job_cards:\n",
    "    # Find the anchor tag for \"Apply\"\n",
    "    apply_link = card.find(\"a\", string=\"Apply\")\n",
    "    # If found, get its href attribute; otherwise, append None\n",
    "    if apply_link:\n",
    "        apply_urls.append(apply_link.get(\"href\"))\n",
    "    else:\n",
    "        apply_urls.append(None)\n",
    "\n",
    "print(\"Apply URLs:\", apply_urls)\n",
    "\n",
    "#Add URLs as column in df\n",
    "jobs_df[\"Apply URL\"] = apply_urls\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb86ef2-215f-4e6c-9a3c-8b7a9839db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Build the \"Apply\" URLs\n",
    "import re\n",
    "\n",
    "constructed_urls = []\n",
    "base_url = \"https://realpython.github.io/fake-jobs/jobs/\"\n",
    "\n",
    "for i, title in enumerate(job_titles):\n",
    "    #Remove unneeded characters\n",
    "    slug = re.sub(r'[^\\w\\s-]', '', title)\n",
    "    #Make lowercase\n",
    "    slug = slug.lower()\n",
    "    #Replace extra whitespace characters with a -\n",
    "    slug = re.sub(r'\\s+', '-', slug)\n",
    "    \n",
    "    #Build the URL\n",
    "    url_constructed = f\"{base_url}{slug}-{i}.html\"\n",
    "    constructed_urls.append(url_constructed)\n",
    "\n",
    "#Print URLs\n",
    "print(\"Constructed URLs:\", constructed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab54c74-c981-434d-b19e-2cf3f48c111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3A Get job page\n",
    "job_url = \"https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html\"\n",
    "job_response = requests.get(job_url)\n",
    "job_soup = BeautifulSoup(job_response.text, \"html.parser\")\n",
    "\n",
    "#Get job description\n",
    "job_description_paragraph = job_soup.find(\"div\", class_=\"content\").find(\"p\").text.strip()\n",
    "\n",
    "print(\"Job Description:\", job_description_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac488fdb-8a95-473d-a497-d23b639c7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3B Get all pages\n",
    "def get_job_description(url):\n",
    "    #Get the job page\n",
    "    response = requests.get(url)\n",
    "    #Parse the page\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Find the container\n",
    "    content_div = soup.find(\"div\", class_=\"content\")\n",
    "    if content_div:\n",
    "        description_p = content_div.find(\"p\")\n",
    "        if description_p:\n",
    "            return description_p.text.strip()\n",
    "    return \"\"\n",
    "\n",
    "#Test function\n",
    "test_url = \"https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html\"\n",
    "job_description = get_job_description(test_url)\n",
    "print(\"Job Description:\", job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d95f0-07e4-4d08-96e4-641b9e67dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3C Use .apply to get job descriptions\n",
    "jobs_df[\"Description\"] = jobs_df[\"Apply URL\"].apply(get_job_description)\n",
    "\n",
    "# Display results\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a5f557a-7387-4fb6-b3c4-d0de556f7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "jobs_df.to_csv(\"jobs_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da6a46-d622-4e6c-91b4-0fdd30fe4cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
